{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "import ipdb\n",
    "from collections import defaultdict\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "'''\n",
    "Here is the class definition for the objective function 1, in which we utilize nonprobabilistic SGD\n",
    "with temporal dynamics and KNN post processing\n",
    "'''\n",
    "class ObjectiveFunction1(object):\n",
    "\tdef __init__(self, training, testing, movie_bias_time_name, features = 10, lmbda = .1):\n",
    "\t\tself.train_data = training\n",
    "\t\tself.test_data = testing\n",
    "\t\tself.num_users = 610\n",
    "\t\tself.num_movies = 9724\n",
    "\t\tself.features = features\n",
    "\t\tself.mu = np.average(self.train_data[:,2]) #### CALCULATE TOTAL AVERAGE RATING HERE!!\n",
    "\t\tself.lmbda = lmbda\n",
    "\t\tself.p = None\n",
    "\t\tself.q = None\n",
    "\t\tself.learning_rate = 0.1\n",
    "\t\tself.movie_bias = pd.read_csv(\"bi_global.csv\")[['val']].to_numpy()\n",
    "\t\tself.user_bias = pd.read_csv(\"bu_global.csv\")[['val']].to_numpy()\n",
    "\t\tself.movie_bias_time = np.zeros((self.num_movies))# np.random.uniform(low=-0.1, high=0.1, size = self.num_movies)\n",
    "\t\tself.user_bi_reg = self.lmbda\n",
    "\t\tself.movie_bi_reg = self.lmbda\n",
    "\t\tself.store_movie_idx(movie_bias_time_name)\n",
    "\n",
    "#This method initalizes the q and p matrices randomly, as well as creates an initial r matrix\n",
    "\n",
    "\tdef matrix_factorization(self):\n",
    "\t\tnp.random.seed(0)\n",
    "\t\tself.p = np.random.normal(scale=1./self.features,size=(self.num_users, self.features))#np.random.uniform(low=-0.5, high=0.5, size=(self.num_users, self.features))\n",
    "\t\tself.q = np.random.normal(scale=1./self.features,size=(self.num_movies, self.features))#np.random.uniform(low=-0.5, high=0.5, size=(self.num_movies, self.features))\n",
    "\t\tself.r = np.matmul(self.p, self.q.T)  #SHAPE: 610 X 9472\n",
    "\n",
    "#This method calculates the temporal dynamics regularization terms\n",
    "\tdef temp_dyn_pred_reg(self, user_id, movie_id, train = True):\n",
    "\t\ttemp_dyn = self.mu + self.movie_bias[movie_id] + self.user_bias[user_id] + self.movie_bias_time[movie_id]\n",
    "\t\treturn temp_dyn\n",
    "\n",
    "#This method maps the movie id's to a continuous movie index for easy manipulation\n",
    "\tdef store_movie_idx(self, movie_bias_time_name):\n",
    "\t\t#df =  pd.read_csv(\"../data/ml-latest-small/movies.csv\")\n",
    "\t\tdf = pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "\t\tidx = [i for i in range(9724)]\n",
    "\t\tself.movie_id2idx = dict(zip(df.movieId.unique(), idx))\n",
    "\t\tdf2 = pd.read_csv(movie_bias_time_name)\n",
    "\t\tnew = []\n",
    "\t\tfor i in range(len(df2['movieId'])):\n",
    "\t\t\tupdate = self.movie_id2idx[df2['movieId'][i]]\n",
    "\t\t\tnew.append(update)\n",
    "\t\tdf2['movie_index'] = new\n",
    "\t\tbibin = df2[['movie_index','bi']].to_numpy()\n",
    "\n",
    "\t\tfor i in range(len(bibin)):\n",
    "\t\t\tself.movie_bias_time[int(bibin[i,0])] = bibin[i,1]\n",
    "\n",
    "# This method trains the objective function via SGD with temporal reg \n",
    "\tdef train_obj_function(self, batch_size = 1, obj_function = 'GD'):\n",
    "\n",
    "\t\tnum_batches = len(self.train_data)//batch_size \n",
    "\t\ttrain_loss_values = np.zeros((num_batches))\n",
    "\t\tvalidation_loss_values = np.zeros((num_batches))\n",
    "\n",
    "\t\ttrain_loss = 0\n",
    "\n",
    "\t\tfor i in range(num_batches):\n",
    "\t\t\t\n",
    "\t\t\t#Inialize gradients\n",
    "\t\t\tdl_dp, dl_dq = 0,0\n",
    "\t\t\t#find gradients\n",
    "\t\t\tfor j in range(batch_size):\n",
    "\n",
    "\t\t\t\tuser_id = self.train_data[i*batch_size+j,:][0] - 1\n",
    "\t\t\t\tmovie_id = self.movie_id2idx[self.train_data[i*batch_size+j,:][1]]\n",
    "\t\t\t\tactual_rating = self.train_data[i*batch_size+j,:][2]\t\t\t\t\n",
    "\n",
    "\t\t\t\tprediction = np.matmul(self.q[movie_id,:], self.p[user_id,:].T) + self.temp_dyn_pred_reg(user_id, movie_id)\n",
    "\t\t\t\tdpred_dq = self.p[user_id,:] \n",
    "\t\t\t\tdpred_dp = self.q[movie_id,:]\n",
    "\n",
    "\t\t\t\tif obj_function == 'GD':\n",
    "\n",
    "\t\t\t\t\ttrain_loss_values[i] = (actual_rating - prediction)**2 + self.GDreg(user_id, movie_id) + self.lmbda*(self.user_bias[user_id]**2 + self.movie_bias[movie_id]**2 + self.movie_bias_time[movie_id]**2)\n",
    "\t\t\t\t\tdl_dq += 2*(actual_rating - prediction)*dpred_dq - self.deriv_GDreg(self.q, movie_id)\n",
    "\t\t\t\t\tdl_dp += 2*(actual_rating - prediction)*dpred_dp - self.deriv_GDreg(self.p, user_id)\n",
    "\n",
    "\t\t\t\t#update p and q matrices via gradient descent, add value to train_loss array for predictionlotting later\n",
    "\t\t\t\tself.p[user_id,:] += self.learning_rate*dl_dp\n",
    "\t\t\t\tself.q[movie_id,:] += self.learning_rate*dl_dq\n",
    "\n",
    "\t\t\t\t#update biase values  via SGD\n",
    "\t\t\t\tdl_dbu = 2*(actual_rating - prediction) - 2*self.user_bi_reg *self.user_bias[user_id]\n",
    "\t\t\t\tdl_dbi = 2*(actual_rating - prediction) - 2*self.movie_bi_reg *self.movie_bias[movie_id]\n",
    "\t\t\t\tdl_dbut = 2*(actual_rating - prediction) - 2*self.lmbda *self.movie_bias_time[movie_id]\n",
    "\t\t\t\tself.movie_bias_time[movie_id] += self.learning_rate*dl_dbut\n",
    "\t\t\t\tself.user_bias[user_id] += self.learning_rate*dl_dbu\n",
    "\t\t\t\tself.movie_bias[movie_id] += self.learning_rate*dl_dbi\n",
    "\t\treturn train_loss_values\n",
    "\n",
    "\tdef GDreg(self, user_id, movie_id):\n",
    "\t\treturn self.lmbda*(np.linalg.norm(self.p[user_id,:])**2 + np.linalg.norm(self.q[movie_id,:])**2)\n",
    "\tdef deriv_GDreg(self,matrix, num):\n",
    "\t\treturn 2*self.lmbda*np.linalg.norm(matrix[num,:])*matrix[num,:]\n",
    "\n",
    "\t#testing loss for plotting\n",
    "\tdef get_validation_loss(self, obj_function ='GD'):\n",
    "\t\ttest_loss = 0\n",
    "\t\ttest_loss_values = np.zeros((len(self.test_data)))\n",
    "\t\tfor j in range(len(self.test_data)):\n",
    "\t\t\tuser_id = self.test_data[j,:][0]-1\n",
    "\t\t\tmovie_id = self.movie_id2idx[self.test_data[j,:][1]]\n",
    "\t\t\tactual_rating = self.test_data[j,:][2]\n",
    "\t\t\tprediction = np.matmul(self.q[movie_id,:], self.p[user_id,:].T) +  self.temp_dyn_pred_reg(user_id, movie_id)\n",
    "\t\t\tif obj_function == 'GD':\n",
    "\t\t\t\ttest_loss_values[j] = (actual_rating - prediction)**2 + self.GDreg(user_id, movie_id)\n",
    "\t\t\t\n",
    "\t\treturn np.average(test_loss_values)\n",
    "\n",
    "\t#Main training method in which you can train for a specified number of epochs and then plot loss + error\n",
    "\tdef train_gd(self, objfunc, num_epochs= 10):\n",
    "\t\t\t\n",
    "\t\tval_loss = np.zeros((num_epochs))\n",
    "\t\ttrain_loss = np.zeros((num_epochs))\n",
    "\n",
    "\t\tval_error = np.zeros((num_epochs))\n",
    "\t\ttrain_error = np.zeros((num_epochs))\n",
    "\n",
    "\t\ttrain_KNN = np.zeros((num_epochs))\n",
    "\t\ttest_KNN = np.zeros((num_epochs))\n",
    "\n",
    "\t\tfor i in range(num_epochs):\n",
    "\t\t\tnp.random.shuffle(self.train_data)\n",
    "\t\t\ttrain_error[i] = self.predict()\n",
    "\t\t\tval_error[i] = self.predict(train=False)\n",
    "\t\t\ttrain_loss_array = self.train_obj_function(obj_function = objfunc)\n",
    "\t\t\ttrain_loss[i] = np.average(train_loss_array)\n",
    "\t\t\tval_loss[i] = self.get_validation_loss(obj_function = objfunc)\n",
    "\t\t\tknnpred = self.get_pred_mat()\n",
    "\t\t\ttrain_KNN[i] = self.KNN_predict()\n",
    "\t\t\ttest_KNN[i] = self.KNN_predict(train=False)\n",
    "\n",
    "\t\t#plot results\n",
    "\t\tx = np.arange(1, num_epochs+1) \n",
    "\n",
    "\t\tfig, (loss, error, KNN) = plt.subplots(1, 3)\n",
    "\t\tfig.suptitle(\"Nonprobabilistic Gradient Descent training\")\n",
    "\t\tloss.set_xlabel(\"# of Epochs\") \n",
    "\t\tloss.set_ylabel(\"loss\") \n",
    "\t\tloss.plot(x,train_loss,label='train loss') \n",
    "\t\tloss.plot(x,val_loss, label='test loss') \n",
    "\t\tloss.legend()\n",
    "\t\terror.set_xlabel(\"# of Epochs\") \n",
    "\t\terror.set_ylabel(\"SGD error\") \n",
    "\t\terror.plot(x,train_error,label='train error') \n",
    "\t\terror.plot(x,val_error, label='test error') \n",
    "\t\terror.legend()\n",
    "\n",
    "\t\tKNN.set_xlabel(\"# of Epochs\") \n",
    "\t\tKNN.set_ylabel(\"KNN + SGD error\") \n",
    "\t\tKNN.plot(x,train_KNN,label='train error') \n",
    "\t\tKNN.plot(x,test_KNN, label='test error') \n",
    "\t\tKNN.legend()\n",
    "\t\tplt.show()\n",
    "\n",
    "\t#this method evaluates your model and outputs your percentage of incorrect predictions for SGD\n",
    "\tdef predict(self, train = True):\n",
    "\t\tself.r = np.matmul(self.p, self.q.T)\n",
    "\t\tif train:\n",
    "\t\t\tdata = self.train_data\n",
    "\t\telse:\n",
    "\t\t\tdata = self.test_data\n",
    "\t\ttotal = len(data)\n",
    "\t\tcorrect = 0\n",
    "\t\tfor i in range(total):\n",
    "\t\t\tuser_id = data[i,0] - 1\n",
    "\t\t\tmovie_id = self.movie_id2idx[data[i,1]]\n",
    "\t\t\tpred = round((self.r[user_id, movie_id] + self.mu +  self.movie_bias_time[movie_id] + self.user_bias[user_id][0] + self.movie_bias[movie_id][0])*2)/2\n",
    "\t\t\tif pred == data[i,2]:\n",
    "\t\t\t\tcorrect +=1\n",
    "\t\treturn (total-correct)/total\n",
    "\n",
    "\t#this method evaluates your model and outputs your percentage of incorrect predictions for KNN post processing\n",
    "\tdef KNN_predict(self, train = True):\n",
    "\t\tif train:\n",
    "\t\t\tdata = self.train_data\n",
    "\t\telse:\n",
    "\t\t\tdata = self.test_data\n",
    "\t\ttotal = len(data)\n",
    "\t\tcorrect = 0\n",
    "\t\tfor i in range(total):\n",
    "\t\t\tuser_id = data[i,0] - 1\n",
    "\t\t\tmovie_id = self.movie_id2idx[data[i,1]]\n",
    "\t\t\tpred = self.pred_mat[user_id, movie_id]\n",
    "\t\t\tif pred == data[i,2]:\n",
    "\t\t\t\tcorrect +=1\n",
    "\t\treturn (total-correct)/total\n",
    "\n",
    "\tdef update_q_matrix(self, q_matrix):\n",
    "\t\tself.q = q_matrix\n",
    "\tdef get_q_matrix(self):\n",
    "\t\treturn self.q\n",
    "\tdef get_p_matrix(self):\n",
    "\t\treturn self.p\n",
    "\n",
    "\t#this method creates the cosine similarity matrix with your learned q matrix\n",
    "\tdef cosine_sim_mat(self):\n",
    "\t\tfrom sklearn.metrics.pairwise import cosine_similarity\n",
    "\t\tself.sim_mat = cosine_similarity(self.q)\n",
    "\t\tself.watch_dict = self.make_watch_dict(self.train_data)\n",
    "\t\tnp.fill_diagonal(self.sim_mat, 0)\n",
    "\n",
    "\t# this method creates the prediction matrix \n",
    "\tdef make_prediction_matrix(self):\n",
    "\t\tself.pred_mat = np.zeros((self.num_users, self.num_movies))\n",
    "\t\tfor i in range(len(self.pred_mat)):\n",
    "\t\t\tfor j in range(len(self.pred_mat[0])):\n",
    "\t\t\t\tself.pred_mat[i,j] = self.argmaxcos(i,j)\n",
    "\t\treturn self.pred_mat\n",
    "\n",
    "\tdef get_pred_mat(self):\n",
    "\t\tself.cosine_sim_mat()\n",
    "\t\tself.make_watch_dict(self.train_data)\n",
    "\t\tself.make_prediction_matrix()\n",
    "\t\treturn self.pred_mat\n",
    "\n",
    "\t#this method supports the prediction matrix creation by getting the argmax of cosine similarity values \n",
    "\tdef argmaxcos(self, i,j):\n",
    "\t\tuser_idx = i + 1\n",
    "\t\tpred_movie_idx = j\n",
    "\t\tall_user_movies_watched = self.watch_dict[i + 1]\n",
    "\t\tif len(all_user_movies_watched)== 0:\n",
    "\t\t\treturn 3.5\n",
    "\n",
    "\t\ttemp = np.zeros((len(all_user_movies_watched)))\n",
    "\t\tfor k in range(len(all_user_movies_watched)):\n",
    "\t\t\tmovie = all_user_movies_watched[k][0]\n",
    "\t\t\tmovie = self.movie_id2idx[movie] # ---> TRANSOFRM\n",
    "\t\t\ttemp[k] = self.sim_mat[pred_movie_idx,movie]\n",
    "\t\tnew_loc = np.argmax(temp)\n",
    "\t\trating = all_user_movies_watched[new_loc][1]\n",
    "\t\treturn rating\n",
    "\n",
    "\t#this method makes a dictionary of all the users in the training set and the movies + respective ratings of all movies that they watched\n",
    "\tdef make_watch_dict(self, data):\n",
    "\t\twatch_dictionary = defaultdict(list)\n",
    "\t\tfor i in range(len(data)):\n",
    "\t\t\tuser_id = data[i,0]\n",
    "\t\t\tmovieId = data[i,1]\n",
    "\t\t\trating = data[i,2]\n",
    "\t\t\twatch_dictionary[user_id].append((movieId, rating))\n",
    "\t\tself.watch_dict = watch_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'train_test_data.xlsx'\n",
    "xl_file = pd.ExcelFile(data_path)\n",
    "df_names= [('bin1_train','bin1_test'),('bin2_train','bin2_test'),('bin3_train','bin3_test')]\n",
    "dfs = {sheet_name: xl_file.parse(sheet_name) \n",
    "    for sheet_name in xl_file.sheet_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin 1\n",
    "bias_time = \"bi_data1.csv\"\n",
    "train_data1 = dfs[df_names[0][0]][['userId','movieId','rating']].to_numpy().astype(int)\n",
    "test_data1 = dfs[df_names[0][1]][['userId','movieId','rating']].to_numpy().astype(int)\n",
    "objfunc1 = ObjectiveFunction1(train_data1, test_data1, bias_time)\n",
    "objfunc1.matrix_factorization()\n",
    "objfunc1.train_gd('GD')\n",
    "q = objfunc1.get_q_matrix()\n",
    "p1 = objfunc1.get_p_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin 2\n",
    "bias_time2 = \"bi_data2.csv\"\n",
    "train_data2 = dfs[df_names[1][0]][['userId','movieId','rating']].to_numpy().astype(int)\n",
    "test_data2 = dfs[df_names[1][1]][['userId','movieId','rating']].to_numpy().astype(int)\n",
    "objfunc2 = ObjectiveFunction1(train_data2, test_data2, bias_time2 )\n",
    "objfunc2.matrix_factorization()\n",
    "objfunc2.update_q_matrix(q)\n",
    "objfunc2.train_gd('GD')\n",
    "q = objfunc2.get_q_matrix()\n",
    "p2 = objfunc2.get_p_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
